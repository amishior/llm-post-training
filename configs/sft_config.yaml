
---

## 4. `configs/sft_config.yaml`

```yaml
model_name_or_path: "Qwen/Qwen2.5-3B-Instruct"
output_dir: "outputs/sft-qwen2.5-3b"
train_file: "data/raw/sft_train.jsonl"
eval_file: "data/raw/sft_eval.jsonl"

max_source_length: 512
max_target_length: 512
max_train_samples: null      # set int for debug mode

per_device_train_batch_size: 2
per_device_eval_batch_size: 2
gradient_accumulation_steps: 8
num_train_epochs: 1
learning_rate: 1e-4
lr_scheduler_type: "cosine"
warmup_ratio: 0.03
weight_decay: 0.01

logging_steps: 50
save_steps: 500
eval_steps: 500
save_total_limit: 3

use_lora: true
lora_r: 64
lora_alpha: 16
lora_dropout: 0.05
lora_target_modules: ["q_proj", "v_proj", "k_proj", "o_proj"]

bf16: true
gradient_checkpointing: true
